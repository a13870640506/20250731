{
    "id": "opt_20250731_113452",
    "date": "20250731_113452",
    "best_params": {
        "d_model": 256,
        "nhead": 1,
        "num_layers": 1,
        "lr": 0.0005155592360037846,
        "weight_decay": 1.816344729485572e-05,
        "batch_size": 16,
        "dropout": 0.05,
        "accumulate_grad_batches": 1
    },
    "metrics": {
        "val_loss": 0.002968437202713069,
        "best_trial": 49
    },
    "trials": [
        {
            "number": 0,
            "value": 0.03169972077012062,
            "d_model": 256,
            "nhead": 4,
            "num_layers": 4,
            "lr": 0.0003667621164430947,
            "weight_decay": 9.861651882125389e-07,
            "batch_size": 16,
            "dropout": 0.05,
            "accumulate_grad_batches": 1
        },
        {
            "number": 1,
            "value": 0.04017684579936459,
            "d_model": 128,
            "nhead": 1,
            "num_layers": 1,
            "lr": 8.941815933090027e-05,
            "weight_decay": 3.952851313085053e-07,
            "batch_size": 16,
            "dropout": 0.05,
            "accumulate_grad_batches": 1
        },
        {
            "number": 2,
            "value": 0.01727192383259535,
            "d_model": 256,
            "nhead": 1,
            "num_layers": 4,
            "lr": 0.0003497973043756731,
            "weight_decay": 1.320821411508229e-07,
            "batch_size": 16,
            "dropout": 0.05,
            "accumulate_grad_batches": 1
        },
        {
            "number": 3,
            "value": 0.16367618942304568,
            "d_model": 128,
            "nhead": 1,
            "num_layers": 2,
            "lr": 1.915952926061176e-05,
            "weight_decay": 2.714875432208703e-07,
            "batch_size": 16,
            "dropout": 0.05,
            "accumulate_grad_batches": 1
        },
        {
            "number": 4,
            "value": 0.09361765330986065,
            "d_model": 256,
            "nhead": 4,
            "num_layers": 2,
            "lr": 1.28194887678965e-05,
            "weight_decay": 2.5650358638769482e-08,
            "batch_size": 16,
            "dropout": 0.05,
            "accumulate_grad_batches": 1
        },
        {
            "number": 5,
            "value": 0.04430210086352685,
            "d_model": 64,
            "nhead": 4,
            "num_layers": 3,
            "lr": 0.0004255391897911783,
            "weight_decay": 3.655199829503638e-05,
            "batch_size": 16,
            "dropout": 0.05,
            "accumulate_grad_batches": 1
        },
        {
            "number": 6,
            "value": 0.03847137331853018,
            "d_model": 128,
            "nhead": 1,
            "num_layers": 4,
            "lr": 6.246480622494929e-05,
            "weight_decay": 5.815306740322004e-08,
            "batch_size": 16,
            "dropout": 0.05,
            "accumulate_grad_batches": 1
        },
        {
            "number": 7,
            "value": 0.020176298313719386,
            "d_model": 256,
            "nhead": 4,
            "num_layers": 1,
            "lr": 5.181922767892622e-05,
            "weight_decay": 7.961231709962136e-08,
            "batch_size": 16,
            "dropout": 0.05,
            "accumulate_grad_batches": 1
        },
        {
            "number": 8,
            "value": 0.018936795949497643,
            "d_model": 256,
            "nhead": 2,
            "num_layers": 2,
            "lr": 0.0007243071058538372,
            "weight_decay": 7.5753973535882444e-06,
            "batch_size": 16,
            "dropout": 0.05,
            "accumulate_grad_batches": 1
        },
        {
            "number": 9,
            "value": 0.018978126347064972,
            "d_model": 64,
            "nhead": 1,
            "num_layers": 1,
            "lr": 0.0002493043555150099,
            "weight_decay": 1.6485578601482125e-07,
            "batch_size": 16,
            "dropout": 0.05,
            "accumulate_grad_batches": 1
        },
        {
            "number": 10,
            "value": 0.011633649865603623,
            "d_model": 256,
            "nhead": 2,
            "num_layers": 3,
            "lr": 0.00019295679097070583,
            "weight_decay": 1.0362978031815315e-08,
            "batch_size": 16,
            "dropout": 0.05,
            "accumulate_grad_batches": 1
        },
        {
            "number": 11,
            "value": 0.007056403727106312,
            "d_model": 256,
            "nhead": 2,
            "num_layers": 3,
            "lr": 0.00017687049804059006,
            "weight_decay": 1.3871885979501776e-08,
            "batch_size": 16,
            "dropout": 0.05,
            "accumulate_grad_batches": 1
        },
        {
            "number": 12,
            "value": 0.006150093258303755,
            "d_model": 256,
            "nhead": 2,
            "num_layers": 3,
            "lr": 0.00015988850122020112,
            "weight_decay": 1.5040368490072616e-08,
            "batch_size": 16,
            "dropout": 0.05,
            "accumulate_grad_batches": 1
        },
        {
            "number": 13,
            "value": 0.014177239636945374,
            "d_model": 256,
            "nhead": 2,
            "num_layers": 3,
            "lr": 0.00014566887629718732,
            "weight_decay": 2.5128516832019322e-08,
            "batch_size": 16,
            "dropout": 0.05,
            "accumulate_grad_batches": 1
        },
        {
            "number": 14,
            "value": 0.013274175635374644,
            "d_model": 256,
            "nhead": 2,
            "num_layers": 3,
            "lr": 3.782093087586631e-05,
            "weight_decay": 1.1201737065336757e-08,
            "batch_size": 16,
            "dropout": 0.05,
            "accumulate_grad_batches": 1
        },
        {
            "number": 15,
            "value": 0.05713638667400707,
            "d_model": 64,
            "nhead": 2,
            "num_layers": 3,
            "lr": 0.00011944313418014924,
            "weight_decay": 4.403842064670493e-06,
            "batch_size": 16,
            "dropout": 0.05,
            "accumulate_grad_batches": 1
        },
        {
            "number": 16,
            "value": 0.13625390646869645,
            "d_model": 256,
            "nhead": 2,
            "num_layers": 2,
            "lr": 0.0008878352808753078,
            "weight_decay": 1.6463795444100732e-06,
            "batch_size": 16,
            "dropout": 0.05,
            "accumulate_grad_batches": 1
        },
        {
            "number": 17,
            "value": 0.008948052082868183,
            "d_model": 256,
            "nhead": 2,
            "num_layers": 4,
            "lr": 8.10288622712366e-05,
            "weight_decay": 4.105680468927893e-08,
            "batch_size": 16,
            "dropout": 0.05,
            "accumulate_grad_batches": 1
        },
        {
            "number": 18,
            "value": 0.07994497690678519,
            "d_model": 128,
            "nhead": 2,
            "num_layers": 3,
            "lr": 3.1795073894029706e-05,
            "weight_decay": 7.107977142687712e-05,
            "batch_size": 16,
            "dropout": 0.05,
            "accumulate_grad_batches": 1
        },
        {
            "number": 19,
            "value": 0.034334564444554204,
            "d_model": 64,
            "nhead": 2,
            "num_layers": 2,
            "lr": 0.00017518632976825288,
            "weight_decay": 5.845587538358105e-07,
            "batch_size": 16,
            "dropout": 0.05,
            "accumulate_grad_batches": 1
        },
        {
            "number": 20,
            "value": 0.025173180079197183,
            "d_model": 256,
            "nhead": 2,
            "num_layers": 4,
            "lr": 0.0004738360711446219,
            "weight_decay": 2.009313485339117e-08,
            "batch_size": 16,
            "dropout": 0.05,
            "accumulate_grad_batches": 1
        },
        {
            "number": 21,
            "value": 0.02091325929059702,
            "d_model": 256,
            "nhead": 2,
            "num_layers": 4,
            "lr": 8.899495715123896e-05,
            "weight_decay": 4.856159145130833e-08,
            "batch_size": 16,
            "dropout": 0.05,
            "accumulate_grad_batches": 1
        },
        {
            "number": 22,
            "value": 0.02985103417407064,
            "d_model": 256,
            "nhead": 2,
            "num_layers": 4,
            "lr": 0.0002600368773877395,
            "weight_decay": 3.836779870312795e-08,
            "batch_size": 16,
            "dropout": 0.05,
            "accumulate_grad_batches": 1
        },
        {
            "number": 23,
            "value": 0.007313359439756502,
            "d_model": 256,
            "nhead": 2,
            "num_layers": 3,
            "lr": 6.908452315400035e-05,
            "weight_decay": 1.0382633643943295e-08,
            "batch_size": 16,
            "dropout": 0.05,
            "accumulate_grad_batches": 1
        },
        {
            "number": 24,
            "value": 0.004527409047381405,
            "d_model": 256,
            "nhead": 2,
            "num_layers": 3,
            "lr": 0.0001259857564774698,
            "weight_decay": 1.2479900335980035e-08,
            "batch_size": 16,
            "dropout": 0.05,
            "accumulate_grad_batches": 1
        },
        {
            "number": 25,
            "value": 0.004556872655966264,
            "d_model": 256,
            "nhead": 2,
            "num_layers": 3,
            "lr": 0.00014059715385669318,
            "weight_decay": 1.1381464793497252e-07,
            "batch_size": 16,
            "dropout": 0.05,
            "accumulate_grad_batches": 1
        },
        {
            "number": 26,
            "value": 0.012902767780949087,
            "d_model": 256,
            "nhead": 2,
            "num_layers": 3,
            "lr": 0.00010935695407003934,
            "weight_decay": 1.354012750627806e-07,
            "batch_size": 16,
            "dropout": 0.05,
            "accumulate_grad_batches": 1
        },
        {
            "number": 27,
            "value": 0.01247361398932031,
            "d_model": 256,
            "nhead": 2,
            "num_layers": 2,
            "lr": 4.298011680454156e-05,
            "weight_decay": 9.083470315644549e-08,
            "batch_size": 16,
            "dropout": 0.05,
            "accumulate_grad_batches": 1
        },
        {
            "number": 28,
            "value": 0.021990341969820505,
            "d_model": 64,
            "nhead": 4,
            "num_layers": 3,
            "lr": 0.0002580706296973517,
            "weight_decay": 2.403065763196672e-07,
            "batch_size": 16,
            "dropout": 0.05,
            "accumulate_grad_batches": 1
        },
        {
            "number": 29,
            "value": 0.01205925495528123,
            "d_model": 128,
            "nhead": 2,
            "num_layers": 3,
            "lr": 0.00012534539711300002,
            "weight_decay": 9.368367033451881e-07,
            "batch_size": 16,
            "dropout": 0.05,
            "accumulate_grad_batches": 1
        },
        {
            "number": 30,
            "value": 0.01656300508800675,
            "d_model": 256,
            "nhead": 4,
            "num_layers": 2,
            "lr": 0.0006035718537095159,
            "weight_decay": 2.8324879952913017e-08,
            "batch_size": 16,
            "dropout": 0.05,
            "accumulate_grad_batches": 1
        },
        {
            "number": 31,
            "value": 0.012635455939316136,
            "d_model": 256,
            "nhead": 2,
            "num_layers": 3,
            "lr": 0.00018271545680352715,
            "weight_decay": 1.7510854853834764e-08,
            "batch_size": 16,
            "dropout": 0.05,
            "accumulate_grad_batches": 1
        },
        {
            "number": 32,
            "value": 0.007733038962161278,
            "d_model": 256,
            "nhead": 2,
            "num_layers": 3,
            "lr": 0.0001469627117748615,
            "weight_decay": 1.702599858468641e-08,
            "batch_size": 16,
            "dropout": 0.05,
            "accumulate_grad_batches": 1
        },
        {
            "number": 33,
            "value": 0.01013506724334815,
            "d_model": 256,
            "nhead": 2,
            "num_layers": 3,
            "lr": 0.0002735128609332472,
            "weight_decay": 9.605150991231463e-08,
            "batch_size": 16,
            "dropout": 0.05,
            "accumulate_grad_batches": 1
        },
        {
            "number": 34,
            "value": 0.02041412829695379,
            "d_model": 256,
            "nhead": 1,
            "num_layers": 3,
            "lr": 0.00035759374753223616,
            "weight_decay": 5.821301928339748e-08,
            "batch_size": 16,
            "dropout": 0.05,
            "accumulate_grad_batches": 1
        },
        {
            "number": 35,
            "value": 0.024653655641219196,
            "d_model": 128,
            "nhead": 2,
            "num_layers": 4,
            "lr": 0.0002065241927162261,
            "weight_decay": 1.6739732782389663e-08,
            "batch_size": 16,
            "dropout": 0.05,
            "accumulate_grad_batches": 1
        },
        {
            "number": 36,
            "value": 0.029000340330907527,
            "d_model": 256,
            "nhead": 1,
            "num_layers": 2,
            "lr": 9.835249701623346e-05,
            "weight_decay": 2.5674028828869344e-07,
            "batch_size": 16,
            "dropout": 0.05,
            "accumulate_grad_batches": 1
        },
        {
            "number": 37,
            "value": 0.007617093204958912,
            "d_model": 256,
            "nhead": 2,
            "num_layers": 3,
            "lr": 0.00012760730317409096,
            "weight_decay": 3.068203178049398e-08,
            "batch_size": 16,
            "dropout": 0.05,
            "accumulate_grad_batches": 1
        },
        {
            "number": 38,
            "value": 0.009212603991139023,
            "d_model": 256,
            "nhead": 4,
            "num_layers": 4,
            "lr": 6.883794446444043e-05,
            "weight_decay": 6.436601572099686e-08,
            "batch_size": 16,
            "dropout": 0.05,
            "accumulate_grad_batches": 1
        },
        {
            "number": 39,
            "value": 0.10971072138122775,
            "d_model": 128,
            "nhead": 2,
            "num_layers": 3,
            "lr": 2.4518010353357716e-05,
            "weight_decay": 1.663677290593423e-08,
            "batch_size": 16,
            "dropout": 0.05,
            "accumulate_grad_batches": 1
        },
        {
            "number": 40,
            "value": 0.018561118090634838,
            "d_model": 256,
            "nhead": 1,
            "num_layers": 2,
            "lr": 5.238732321683957e-05,
            "weight_decay": 2.1974171141760558e-06,
            "batch_size": 16,
            "dropout": 0.05,
            "accumulate_grad_batches": 1
        },
        {
            "number": 41,
            "value": 0.013464479638701853,
            "d_model": 256,
            "nhead": 2,
            "num_layers": 3,
            "lr": 7.687574636048608e-05,
            "weight_decay": 1.1097423737607789e-08,
            "batch_size": 16,
            "dropout": 0.05,
            "accumulate_grad_batches": 1
        },
        {
            "number": 42,
            "value": 0.008682643725906554,
            "d_model": 256,
            "nhead": 2,
            "num_layers": 3,
            "lr": 6.033222888102033e-05,
            "weight_decay": 1.1098950225546373e-08,
            "batch_size": 16,
            "dropout": 0.05,
            "accumulate_grad_batches": 1
        },
        {
            "number": 43,
            "value": 0.03246565615100896,
            "d_model": 256,
            "nhead": 2,
            "num_layers": 3,
            "lr": 0.00015824470380916667,
            "weight_decay": 3.659150048562892e-08,
            "batch_size": 16,
            "dropout": 0.05,
            "accumulate_grad_batches": 1
        },
        {
            "number": 44,
            "value": 0.00815713099505314,
            "d_model": 256,
            "nhead": 2,
            "num_layers": 3,
            "lr": 0.00022514853034083109,
            "weight_decay": 4.040671210416587e-07,
            "batch_size": 16,
            "dropout": 0.05,
            "accumulate_grad_batches": 1
        },
        {
            "number": 45,
            "value": 0.2537885658333407,
            "d_model": 64,
            "nhead": 2,
            "num_layers": 3,
            "lr": 1.4762692371541875e-05,
            "weight_decay": 2.1933572712784137e-08,
            "batch_size": 16,
            "dropout": 0.05,
            "accumulate_grad_batches": 1
        },
        {
            "number": 46,
            "value": 0.03118480895371998,
            "d_model": 256,
            "nhead": 4,
            "num_layers": 3,
            "lr": 0.0001016372860926529,
            "weight_decay": 1.1052268128853793e-08,
            "batch_size": 16,
            "dropout": 0.05,
            "accumulate_grad_batches": 1
        },
        {
            "number": 47,
            "value": 0.005716885166133151,
            "d_model": 256,
            "nhead": 2,
            "num_layers": 2,
            "lr": 0.00032626904828522463,
            "weight_decay": 1.0103510318453866e-05,
            "batch_size": 16,
            "dropout": 0.05,
            "accumulate_grad_batches": 1
        },
        {
            "number": 48,
            "value": 0.005979984385810573,
            "d_model": 256,
            "nhead": 1,
            "num_layers": 1,
            "lr": 0.0003290151726105402,
            "weight_decay": 1.697298814766548e-05,
            "batch_size": 16,
            "dropout": 0.05,
            "accumulate_grad_batches": 1
        },
        {
            "number": 49,
            "value": 0.002968437202713069,
            "d_model": 256,
            "nhead": 1,
            "num_layers": 1,
            "lr": 0.0005155592360037846,
            "weight_decay": 1.816344729485572e-05,
            "batch_size": 16,
            "dropout": 0.05,
            "accumulate_grad_batches": 1
        }
    ]
}